import os
import sys
import json
import re
from difflib import SequenceMatcher
from typing import Dict, List, Tuple
from llama_cpp import Llama

# =========================
# Paths
# =========================
MODEL_PATH = "/home/dmachine/Documents/RaspDbot/raspdbot-star.Q4_K_M.gguf"
JSONL_PATH = "/home/dmachine/Documents/RaspDbot/raspDbot_star_training.jsonl"

# =========================
# Greetings
# =========================
GREETINGS = [
    "xin chÃ o", "chÃ o", "chÃ o báº¡n", "hello", "hi", "hey", "alo",
    "good morning", "good afternoon", "good evening",
    "báº¡n lÃ  ai", "giá»›i thiá»‡u"
]

GREETING_RESPONSE = (
    "Xin chÃ o ğŸ‘‹ TÃ´i lÃ  chatbot chuyÃªn gia vá» mÃ´ hÃ¬nh xe tá»± hÃ nh RaspDbot-Star.\n"
    "TÃ´i cÃ³ thá»ƒ tráº£ lá»i cÃ¡c cÃ¢u há»i vá» pháº§n cá»©ng, pháº§n má»m, cáº£m biáº¿n, AI, "
    "Ä‘iá»u khiá»ƒn vÃ  cÃ¡ch váº­n hÃ nh cá»§a RaspDbot-Star.\n"
    "Báº¡n Ä‘ang muá»‘n há»i váº¥n Ä‘á» gÃ¬ liÃªn quan Ä‘áº¿n RaspDbot-Star?"
)

# =========================
# Confirmation words
# =========================
CONFIRM_WORDS = [
    "Ä‘Ãºng", "Ä‘Ãºng váº­y", "á»«", "uh", "cÃ³", "pháº£i", "yes", "ok", "Ä‘Ãºng rá»“i"
]

# =========================
# Clarify session state
# =========================
clarify_sessions: Dict[str, Dict[str, str]] = {}
# { session_id: { "count": int, "last_question": str } }

# =========================
# Base system prompt
# =========================
BASE_SYSTEM_PROMPT = (
    "Báº¡n lÃ  chatbot chuyÃªn gia vá» mÃ´ hÃ¬nh xe tá»± hÃ nh RaspDbot-Star.\n"
    "Báº¡n Ä‘Æ°á»£c cung cáº¥p má»™t táº­p dá»¯ liá»‡u gá»“m cÃ¡c cÃ¢u há»i vÃ  cÃ¢u tráº£ lá»i "
    "liÃªn quan Ä‘áº¿n RaspDbot-Star.\n\n"

    "QUY Táº®C Báº®T BUá»˜C:\n"
    "1. Báº¡n PHáº¢I Ä‘á»c ká»¹ toÃ n bá»™ dá»¯ liá»‡u Ä‘Æ°á»£c cung cáº¥p.\n"
    "2. Náº¿u cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng gáº§n nghÄ©a hoáº·c liÃªn quan Ä‘áº¿n dá»¯ liá»‡u, "
    "hÃ£y sá»­ dá»¥ng dá»¯ liá»‡u Ä‘Ã³ Ä‘á»ƒ tráº£ lá»i, dÃ¹ cÃ¡ch diá»…n Ä‘áº¡t khÃ¡c.\n"
    "3. KhÃ´ng yÃªu cáº§u cÃ¢u há»i pháº£i trÃ¹ng y nguyÃªn má»›i Ä‘Æ°á»£c tráº£ lá»i.\n"
    "4. KhÃ´ng Ä‘Æ°á»£c bá»‹a thÃ´ng tin ngoÃ i dá»¯ liá»‡u.\n\n"

    "Xá»¬ LÃ CÃ‚U Há»I NGOÃ€I Dá»® LIá»†U:\n"
    "- Náº¿u chÆ°a rÃµ cÃ³ liÃªn quan Ä‘áº¿n RaspDbot-Star hay khÃ´ng, "
    "hÃ£y há»i láº¡i Ä‘á»ƒ lÃ m rÃµ (tá»‘i Ä‘a 2 láº§n).\n"
    "- Náº¿u ngÆ°á»i dÃ¹ng xÃ¡c nháº­n cÃ³ liÃªn quan, "
    "hÃ£y cá»‘ gáº¯ng tráº£ lá»i dá»±a trÃªn dá»¯ liá»‡u hiá»‡n cÃ³.\n"
    "- Náº¿u sau 2 láº§n váº«n khÃ´ng liÃªn quan, tráº£ lá»i Ä‘Ãºng cÃ¢u: "
    "'TÃ´i khÃ´ng cÃ³ thÃ´ng tin nÃ y.'\n"
)

# =========================
# Helpers
# =========================
def normalize(text: str) -> str:
    text = text.lower().strip()
    text = re.sub(r"\s+", " ", text)
    return text

def is_greeting(text: str) -> bool:
    t = normalize(text)
    return any(g == t or g in t for g in GREETINGS)

def is_confirm(text: str) -> bool:
    t = normalize(text)
    return any(w == t or w in t for w in CONFIRM_WORDS)

def load_jsonl(path: str) -> List[Dict]:
    """
    Há»— trá»£ JSONL format phá»• biáº¿n:
    1) {"prompt": "...", "completion": "..."}
    2) {"question": "...", "answer": "..."}
    3) {"messages":[{"role":"user","content":"..."},{"role":"assistant","content":"..."}]}
    4) Fallback: {"instruction": "...", "response": "..."} hoáº·c {"input": "...", "output": "..."}
    """
    data = []
    with open(path, "r", encoding="utf-8") as f:
        for i, line in enumerate(f, start=1):
            line = line.strip()
            if not line:
                continue
            try:
                data.append(json.loads(line))
            except json.JSONDecodeError:
                print(f"[WARN] DÃ²ng {i} khÃ´ng pháº£i JSON há»£p lá»‡, bá» qua.")
    return data

def extract_qa(item: Dict) -> Tuple[str, str]:
    if "prompt" in item and "completion" in item:
        return str(item["prompt"]).strip(), str(item["completion"]).strip()

    if "question" in item and "answer" in item:
        return str(item["question"]).strip(), str(item["answer"]).strip()

    if "instruction" in item and "response" in item:
        return str(item["instruction"]).strip(), str(item["response"]).strip()

    if "input" in item and "output" in item:
        return str(item["input"]).strip(), str(item["output"]).strip()

    if "messages" in item and isinstance(item["messages"], list):
        user_parts, assistant_parts = [], []
        for m in item["messages"]:
            if not isinstance(m, dict):
                continue
            role = m.get("role", "")
            content = str(m.get("content", "")).strip()
            if role == "user":
                user_parts.append(content)
            elif role == "assistant":
                assistant_parts.append(content)
        return "\n".join(user_parts).strip(), "\n".join(assistant_parts).strip()

    return "", ""

def similarity(a: str, b: str) -> float:
    return SequenceMatcher(None, normalize(a), normalize(b)).ratio()

def top_k_context(question: str, qa_pairs: List[Tuple[str, str]], k: int = 5) -> List[Tuple[float, str, str]]:
    scored = []
    for q, a in qa_pairs:
        if not q or not a:
            continue
        s = similarity(question, q)
        scored.append((s, q, a))
    scored.sort(key=lambda x: x[0], reverse=True)
    return scored[:k]

def build_context_text(top: List[Tuple[float, str, str]]) -> str:
    lines = []
    for idx, (s, q, a) in enumerate(top, start=1):
        lines.append(f"[Máº«u {idx} | score={s:.2f}]\nHá»i: {q}\nÄÃ¡p: {a}\n")
    return "\n".join(lines).strip()

def build_prompt(question: str, context: str) -> str:
    return f"""### System:
{BASE_SYSTEM_PROMPT}

### Dá»® LIá»†U THAM CHIáº¾U (trÃ­ch tá»« JSONL):
{context}

### User:
{question}

### Assistant:
"""

def should_clarify(best_score: float) -> bool:
    # NgÆ°á»¡ng báº¡n cÃ³ thá»ƒ chá»‰nh:
    # - >=0.60: khÃ¡ cháº¯c liÃªn quan
    # - 0.45..0.60: lÆ°ng chá»«ng, há»i láº¡i
    # - <0.45: nhiá»u kháº£ nÄƒng ngoÃ i dá»¯ liá»‡u
    return best_score < 0.60

def next_clarify_question() -> str:
    return (
        "CÃ¢u há»i nÃ y cÃ³ liÃªn quan Ä‘áº¿n RaspDbot-Star khÃ´ng?\n"
        "Náº¿u cÃ³, báº¡n nÃ³i 'Ä‘Ãºng' vÃ  mÃ´ táº£ rÃµ hÆ¡n (vÃ­ dá»¥: pháº§n cá»©ng/cáº£m biáº¿n/Ä‘iá»u khiá»ƒn/tá»‘c Ä‘á»™...)."
    )

# =========================
# Main
# =========================
def main():
    if not os.path.exists(MODEL_PATH):
        print("KhÃ´ng tÃ¬m tháº¥y model:", MODEL_PATH)
        sys.exit(1)

    if not os.path.exists(JSONL_PATH):
        print("KhÃ´ng tÃ¬m tháº¥y JSONL:", JSONL_PATH)
        sys.exit(1)

    raw = load_jsonl(JSONL_PATH)
    qa_pairs: List[Tuple[str, str]] = []
    for item in raw:
        q, a = extract_qa(item)
        if q and a:
            qa_pairs.append((q, a))

    if not qa_pairs:
        print("KhÃ´ng trÃ­ch Ä‘Æ°á»£c Q/A tá»« JSONL. Kiá»ƒm tra format file.")
        sys.exit(1)

    llm = Llama(
        model_path=MODEL_PATH,
        n_ctx=4096,
        n_threads=os.cpu_count() or 4,
        n_gpu_layers=0,
        verbose=False
    )

    session_id = "terminal"  # báº¡n cÃ³ thá»ƒ Ä‘á»•i/nhÃ¢n báº£n náº¿u lÃ m nhiá»u session
    clarify_sessions[session_id] = {"count": 0, "last_question": ""}

    print("ğŸ¤– RaspDbot-Star Chat (JSONL) â€” gÃµ 'exit' Ä‘á»ƒ thoÃ¡t\n")

    while True:
        user_text = input("Báº¡n: ").strip()
        if not user_text:
            continue
        if user_text.lower() in ("exit", "quit", "q"):
            break

        # 1) Greeting
        if is_greeting(user_text):
            print(f"\nBot: {GREETING_RESPONSE}\n")
            continue

        # 2) Clarify flow: náº¿u Ä‘ang há»i láº¡i mÃ  user confirm
        if clarify_sessions[session_id]["count"] > 0 and is_confirm(user_text):
            # user xÃ¡c nháº­n liÃªn quan -> dÃ¹ng cÃ¢u há»i trÆ°á»›c Ä‘Ã³ Ä‘á»ƒ tráº£ lá»i
            user_text = clarify_sessions[session_id]["last_question"]
            clarify_sessions[session_id]["count"] = 0
            clarify_sessions[session_id]["last_question"] = ""

        # 3) Láº¥y context gáº§n nháº¥t
        top = top_k_context(user_text, qa_pairs, k=5)
        best_score = top[0][0] if top else 0.0

        # 4) Náº¿u khÃ´ng cháº¯c liÃªn quan -> há»i láº¡i tá»‘i Ä‘a 2 láº§n
        if should_clarify(best_score):
            c = int(clarify_sessions[session_id]["count"])
            if c < 2:
                clarify_sessions[session_id]["count"] = c + 1
                clarify_sessions[session_id]["last_question"] = user_text
                print(f"\nBot: {next_clarify_question()}\n")
                continue
            else:
                # quÃ¡ 2 láº§n váº«n khÃ´ng liÃªn quan
                clarify_sessions[session_id]["count"] = 0
                clarify_sessions[session_id]["last_question"] = ""
                print("\nBot: TÃ´i khÃ´ng cÃ³ thÃ´ng tin nÃ y.\n")
                continue

        # 5) Build prompt + generate
        context = build_context_text(top)
        prompt = build_prompt(user_text, context)

        out = llm(
            prompt,
            max_tokens=256,
            temperature=0.3,  # bÃ¡m dá»¯ liá»‡u hÆ¡n
            top_p=0.9,
            stop=["### User:", "### System:", "### Assistant:", "### Dá»® LIá»†U THAM CHIáº¾U"],
        )

        answer = out["choices"][0]["text"].strip()
        if not answer:
            answer = "ChÆ°a Ä‘á»§ dá»¯ liá»‡u."

        print(f"\nBot: {answer}\n")

if __name__ == "__main__":
    main()
