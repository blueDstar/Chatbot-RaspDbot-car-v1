import os
from typing import List, Dict, Optional
from llama_cpp import Llama

# =========================
# Greetings (cháº·n báº±ng code)
# =========================
GREETINGS = {
    "hi", "hello", "hey", "alo", "chÃ o", "xin chÃ o", "chÃ o báº¡n", "yo"
}

# =========================
# Keywords cáº§n dá»¯ liá»‡u realtime
# =========================
NEED_DATA_KEYWORDS = [
    "vá»‹ trÃ­", "gps", "tá»‘c Ä‘á»™ hiá»‡n táº¡i", "tá»‘c Ä‘á»™",
    "imu", "lidar", "camera", "log", "pin", "battery"
]

# =========================
# Prompt / Stop tokens
# =========================
SYSTEM_PROMPT = (
    "Báº¡n lÃ  trá»£ lÃ½ ká»¹ thuáº­t cho xe tá»± hÃ nh RaspDbot-Car.\n"
    "KHI TRáº¢ Lá»œI:\n"
    "- LuÃ´n xÆ°ng lÃ  \"tÃ´i\" vÃ  gá»i ngÆ°á»i dÃ¹ng lÃ  \"báº¡n\".\n"
    "- Tráº£ lá»i ngáº¯n gá»n, Ä‘Ãºng trá»ng tÃ¢m; Æ°u tiÃªn gáº¡ch Ä‘áº§u dÃ²ng khi liá»‡t kÃª.\n"
    "\n"
    "QUY Táº®C Báº®T BUá»˜C:\n"
    "1) Chá»‰ tráº£ lá»i dá»±a trÃªn thÃ´ng tin báº¡n cung cáº¥p hoáº·c kiáº¿n thá»©c chung vá» robot/xe tá»± hÃ nh.\n"
    "2) Náº¿u cÃ¢u há»i cáº§n dá»¯ liá»‡u cá»¥ thá»ƒ (vá»‹ trÃ­ xe, tá»‘c Ä‘á»™ hiá»‡n táº¡i, cáº£m biáº¿n, log, cáº¥u hÃ¬nh) "
    "mÃ  báº¡n chÆ°a Ä‘Æ°a dá»¯ liá»‡u => tráº£ lá»i: \"TÃ´i chÆ°a cÃ³ dá»¯ liá»‡u Ä‘Ã³\" vÃ  há»i báº¡n cáº§n cung cáº¥p gÃ¬.\n"
    "3) KhÃ´ng Ä‘Æ°á»£c tá»± bá»‹a sá»‘ liá»‡u/Ä‘á»‹a Ä‘iá»ƒm (vÃ­ dá»¥: \"5.000m\", \"Ä‘Æ°á»ng 1\", GPS...) náº¿u khÃ´ng cÃ³ dá»¯ liá»‡u.\n"
    "4) Náº¿u báº¡n chÃ o há»i ngáº¯n (vd: \"alo\", \"hi\"), tÃ´i chá»‰ chÃ o láº¡i vÃ  gá»£i Ã½ báº¡n há»i vá» RaspDbot-Car.\n"
)

# Stop tokens cÃ³ newline Ä‘á»ƒ cháº·n multi-turn "### Assistant:" sinh láº¡i
STOP_TOKENS = ["\n### User:", "\n### System:", "\n### Assistant:"]


def build_prompt(history: List[Dict[str, str]]) -> str:
    parts: List[str] = []
    parts.append("### System:\n" + SYSTEM_PROMPT.strip() + "\n")

    for m in history:
        if m["role"] == "user":
            parts.append("### User:\n" + m["content"].strip() + "\n")
        else:
            parts.append("### Assistant:\n" + m["content"].strip() + "\n")

    parts.append("### Assistant:\n")
    return "\n".join(parts)


class RaspDbotEngine:
    def __init__(
        self,
        model_path: str,
        n_ctx: int = 2048,
        n_threads: Optional[int] = None,
        n_gpu_layers: int = 0,
    ):
        self.model_path = model_path
        if not os.path.exists(self.model_path):
            raise FileNotFoundError(f"KhÃ´ng tÃ¬m tháº¥y model: {self.model_path}")

        self.llm = Llama(
            model_path=self.model_path,
            n_ctx=n_ctx,
            n_threads=n_threads or (os.cpu_count() or 4),
            n_gpu_layers=n_gpu_layers,
            verbose=False,
        )
        self.history: List[Dict[str, str]] = []

    def ask(self, user_text: str) -> str:
        user_text = (user_text or "").strip()
        if not user_text:
            return "Báº¡n hÃ£y nháº­p cÃ¢u há»i trÆ°á»›c nhÃ©."

        low = user_text.lower()

        # 1) Greeting: tráº£ lá»i ngay, khÃ´ng gá»i LLM
        if low in GREETINGS:
            return "Xin chÃ o ðŸ‘‹ TÃ´i Ä‘Ã¢y. Báº¡n muá»‘n há»i gÃ¬ vá» RaspDbot-Car?"

        # 2) Realtime data: tráº£ lá»i cháº¯c cháº¯n, khÃ´ng gá»i LLM
        if any(k in low for k in NEED_DATA_KEYWORDS):
            return (
                "TÃ´i chÆ°a cÃ³ dá»¯ liá»‡u realtime cá»§a xe (GPS/tá»‘c Ä‘á»™/cáº£m biáº¿n/log).\n"
                "Báº¡n hÃ£y gá»­i má»™t trong cÃ¡c thÃ´ng tin sau Ä‘á»ƒ tÃ´i phÃ¢n tÃ­ch:\n"
                "- Log/telemetry (JSON/text)\n"
                "- ThÃ´ng sá»‘ cáº£m biáº¿n\n"
                "- Tráº¡ng thÃ¡i hiá»‡n táº¡i (vá»‹ trÃ­/tá»‘c Ä‘á»™/pin)\n"
            )

        self.history.append({"role": "user", "content": user_text})
        prompt = build_prompt(self.history)

        out = self.llm(
            prompt,
            max_tokens=256,
            temperature=0.35,
            top_p=0.9,
            top_k=50,
            repeat_penalty=1.15,
            stop=STOP_TOKENS,
        )

        answer = (out["choices"][0]["text"] or "").strip()
        if not answer:
            answer = "(TÃ´i khÃ´ng sinh Ä‘Æ°á»£c cÃ¢u tráº£ lá»i â€” báº¡n thá»­ tÄƒng max_tokens hoáº·c Ä‘á»•i prompt template.)"

        # 3) Cáº¯t sáº¡ch náº¿u model lá»¡ in marker hoáº·c tá»± chat tiáº¿p
        for cut in ["\n### ", "### Assistant:", "### User:", "### System:"]:
            idx = answer.find(cut)
            if idx != -1:
                answer = answer[:idx].strip()
                break

        # 4) Ã‰p nháº¹ xÆ°ng hÃ´
        answer = (
            answer.replace("MÃ¬nh ", "TÃ´i ")
                  .replace("mÃ¬nh ", "tÃ´i ")
                  .replace("Tá»› ", "TÃ´i ")
                  .replace("tá»› ", "tÃ´i ")
        )

        self.history.append({"role": "assistant", "content": answer})
        return answer

    def reset(self):
        self.history = []

    def export_text(self) -> str:
        lines = []
        for m in self.history:
            prefix = "ðŸ‘¤ Báº¡n" if m["role"] == "user" else "ðŸ¤– TÃ´i"
            lines.append(f"{prefix}: {m['content']}")
        return "\n\n".join(lines)

    def to_json(self) -> dict:
        return {
            "model_path": self.model_path,
            "history": self.history,
        }

    def load_json(self, data: dict):
        hist = data.get("history", [])
        if isinstance(hist, list):
            self.history = [
                {"role": str(m.get("role", "")), "content": str(m.get("content", ""))}
                for m in hist
                if isinstance(m, dict)
            ]
